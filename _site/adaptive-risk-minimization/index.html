<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/blog/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">

    <!--Favicon-->
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-16x16.png" sizes="16x16" />

    <!-- Canonical -->
    <link rel="canonical" href="http://0.0.0.0:4000/blog/adaptive-risk-minimization/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="The Stanford AI Lab Blog" href="http://0.0.0.0:4000/blog/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/font-awesome.min.css">
    
    <!-- Bootstrap-3.3.7 isolation CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">


    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    
    <!-- JQuery 2.2.4 -->
    <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/bigfoot-number.css">
    <script type="text/javascript" src="/blog/assets/js/vendor/bigfoot.min.js"></script>
    <script type="text/javascript">
    $(document).ready(function() { 
      $.bigfoot();
      
    window.onload = function() {

        var videos = document.getElementsByTagName("video"),
            fraction = 0.8;

        function checkScroll() {

            for (var i = 0; i < videos.length; i++) {

                var video = videos[i];

                var x = video.offsetLeft,
                    y = video.offsetTop,
                    w = video.offsetWidth,
                    h = video.offsetHeight,
                    r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }

        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    }
    }); 
    </script>
    


    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/katex.min.css">
    <script src="/blog/assets/js/vendor/katex.min.js">
    </script>
    
    
    
    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-129018108-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Adapting on the Fly to Test Time Distribution Shift | SAIL Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Adapting on the Fly to Test Time Distribution Shift" />
<meta name="author" content="<a href="http://marvinzhang.com">Marvin Zhang</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to distribution shift. One solution for this challenge is to learn an adaptive model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users without labels?" />
<meta property="og:description" content="Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to distribution shift. One solution for this challenge is to learn an adaptive model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users without labels?" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/adaptive-risk-minimization/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/adaptive-risk-minimization/" />
<meta property="og:site_name" content="SAIL Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-05T00:00:00-08:00" />
<script type="application/ld+json">
{"description":"Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to distribution shift. One solution for this challenge is to learn an adaptive model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users without labels?","author":{"@type":"Person","name":"<a href=\"http://marvinzhang.com\">Marvin Zhang</a>"},"@type":"BlogPosting","url":"http://0.0.0.0:4000/blog/adaptive-risk-minimization/","headline":"Adapting on the Fly to Test Time Distribution Shift","dateModified":"2020-11-05T00:00:00-08:00","datePublished":"2020-11-05T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/blog/adaptive-risk-minimization/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    
    <!-- Manual seo tags -->
    <title>Adapting on the Fly to Test Time Distribution Shift | The Stanford AI Lab Blog</title>
    <meta name="description" content="We meta-learn models that can use unlabeled test data to adapt to group distribution shift.">
    
    <!-- Twitter Cards -->
    <meta name="twitter:title" content="Adapting on the Fly to Test Time Distribution Shift">
    
    <meta name="twitter:description" content="We meta-learn models that can use unlabeled test data to adapt to group distribution shift.">
    
    <meta name="twitter:creator" content="@StanfordAILab">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://0.0.0.0:4000/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/intro.png">
    <meta name="og:image" content="http://0.0.0.0:4000/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/intro.png">
    
</head>

  <body class="post-body">
      <!-- Toggle menu -->
<header class="site-header">

<nav class="clear navbar navbar-expand-lg navbar-light bg-white flex-column flex-md-row bd-navbar fixed-top" id="main_nav">
  
  <div class="container">

    <a class="navbar-brand mr-0 mr-md-2 text-black d-flex align-items-center" href="/blog/" aria-label="Bootstrap">
    
	  <div class="branding">
	    <a href="http://ai.stanford.edu/">
	      <img class="avatar" src="/blog/assets/img/sail-logo.png" alt=""/>
		  </a>

      <a href="/blog/">
	      <h1 class="site-title">
			    The Stanford AI Lab Blog
		    </h1> 
		  </a>
	  </div>
    
    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse" id="navbarResponsive">

      <ul class="navbar-nav ml-auto">
      
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/about">About</a>
      </li>
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
        <div class="dropdown-menu">
        <a class="dropdown-item" href="/blog/">All</a>
        <a class="dropdown-item" href="/blog/conferences">Conferences</a>
        <a class="dropdown-item" href="/blog/vision">Computer Vision</a>
        <a class="dropdown-item" href="/blog/robotics">Robotics</a>
        <a class="dropdown-item" href="/blog/nlp">NLP</a>
        <a class="dropdown-item" href="/blog/ml">Machine Learning</a>
        <a class="dropdown-item" href="/blog/rl">Reinforcement Learning</a>

        </div>
      </li>
        
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/subscribe">Subscribe</a>
      </li>
      
      
      <li class="nav-item">
      <a class="nav-link" href="http://ai.stanford.edu/">SAIL</a>
      </li>
      
      </ul> 

    </div>

  </div>
</nav>

</header>

  
    <div class="content">
      

<article>

  <header id="main">
    
    <h1 id="post_title">Adapting on the Fly to Test Time Distribution Shift</h1>
    <p class="meta">
    <a href="http://marvinzhang.com">Marvin Zhang</a>
    <div class="post-date">November 5, 2020</div>
    </p>
  <hr>
  </header>


  <section class="post-content">
  
    <p>Imagine that you are building the next generation machine learning model for handwriting transcription. Based on previous iterations of your product, you have identified a key challenge for this rollout: after deployment, new end users often have different and unseen handwriting styles, leading to <em>distribution shift</em>. One solution for this challenge is to learn an <em>adaptive</em> model that can specialize and adjust to each user’s handwriting style over time. This solution seems promising, but it must be balanced against concerns about ease of use: requiring users to provide feedback to the model may be cumbersome and hinder adoption. Is it possible instead to learn a model that can adapt to new users <em>without labels</em>?</p>

<p>In many scenarios, including this example, the answer is “yes”. Consider the ambiguous example shown enlarged in the figure below. Is this character a “2” with a loop or a <a href="https://en.wikipedia.org/wiki/A#English">double-storey “a”</a>? For a non adaptive model that pays attention to the biases in the training data, the reasonable prediction would be “2”. However, even without labels, we can extract useful information from the user’s other examples: an adaptive model, for example, can observe that this user has written “2”s without loops and conclude that this character is thus more likely to be “a”.</p>

<figure class="figure"><div class="figure__main">
<p><img width="100%" src="/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/intro.gif" /></p>
</div></figure>

<p>Handling the distribution shift that arises from deploying a model to new users is an important motivating example for unlabeled adaptation. But, this is far from the only example. In an ever-changing world, autonomous cars need to adapt to new weather conditions and locations, image classifiers need to adapt to new cameras with different intrinsics, and recommender systems need to adapt to users’ evolving preferences. Humans have demonstrated the ability to <a href="http://pages.cs.wisc.edu/~jerryzhu/pub/tie.pdf">adapt without labels</a> by inferring information from the distribution of test examples. Can we develop methods that can allow machine learning models to do the same?</p>

<p>This question has enjoyed growing attention from researchers, with a number of recent works proposing methods for unlabeled test time adaptation. In this post, I will survey these works as well as other prominent frameworks for handling distribution shift. With this broader context in mind, I will then discuss our recent work (see the paper <a href="https://arxiv.org/abs/2007.02931">here</a> and the code <a href="https://github.com/henrikmarklund/arm">here</a>), in which we propose a problem formulation that we term <strong>adaptive risk minimization</strong>, or ARM.</p>

<h2 id="diving-into-distribution-shift">Diving into Distribution Shift</h2>

<p>The vast majority of work in machine learning follows the canonical framework of <strong>empirical risk minimization</strong>, or ERM. ERM methods assume that there is no distribution shift, so the test distribution exactly matches the training distribution. This assumption simplifies the development and analysis of powerful machine learning methods but, as discussed above, is routinely violated in real-world applications. To move beyond ERM and learn models that generalize in the face of distribution shift, we must introduce additional assumptions. However, we must carefully choose these assumptions such that they are still realistic and broadly applicable.</p>

<p>How do we maintain realism and applicability? One answer is to model the assumptions on the conditions that machine learning systems face in the real world. For example, in the ERM setting, models are evaluated on each test point one at a time, but in the real world, these test points are often available sequentially or in <em>batches</em>. For handwriting transcription, for example, we can imagine collecting entire sentences and paragraphs from new users. If there is distribution shift, observing multiple test points can be useful either to infer the test distribution or otherwise adapt the model to this new distribution, even in the absence of labels.</p>

<p>Many recent methods that use this assumption can be classified as <strong>test time adaptation</strong>, including <a href="https://arxiv.org/abs/1603.04779">batch normalization</a>, <a href="https://arxiv.org/abs/1802.03916">label shift estimation</a>, <a href="https://arxiv.org/abs/1909.13231">rotation prediction</a>, <a href="https://arxiv.org/abs/2006.10726">entropy minimization</a>, and more. Oftentimes, these methods build in strong inductive biases that enable useful adaptation; for example, rotation prediction is well aligned with many image classification tasks. But these methods generally either propose heuristic training procedures or do not consider the training procedure at all, relying instead on pretrained models.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> This begs the question: can test time adaptation be further enhanced by improved training, such that the model can make better use of the adaptation procedure?</p>

<p>We can gain insight into this question by investigating other prominent frameworks for handling distribution shift and, in particular, the assumptions these frameworks make. In real-world applications, the training data generally does not consist only of input label pairs; instead, there are additional <em>meta-data</em> associated with each example, such as time and location, or the particular user in the handwriting example. These meta-data can be used to organize the training data into <em>groups</em>,<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> and a common assumption in a number of frameworks is that the test time distribution shifts represent either new group distributions or new groups altogether. This assumption still allows for a wide range of realistic distribution shifts and has driven the development of numerous practical methods.</p>

<p>For example, <strong>domain adaptation</strong> methods typically assume access to two training groups: source and target data, with the latter being drawn from the test distribution. Thus, these methods augment training to focus on the target distribution, such as through <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.370.4921&amp;rep=rep1&amp;type=pdf">importance</a> <a href="http://sifaka.cs.uiuc.edu/czhai/pub/acl07.pdf">weighting</a> or learning <a href="https://arxiv.org/abs/1505.07818">invariant</a> <a href="https://arxiv.org/abs/1702.05464">representations</a>. Methods for <a href="http://papers.neurips.cc/paper/3019-mixture-regression-for-covariate-shift.pdf"><strong>group</strong></a> <a href="https://arxiv.org/abs/1611.02041"><strong>distributionally robust</strong></a> <a href="https://arxiv.org/abs/1911.08731"><strong>optimization</strong></a> and <a href="https://papers.nips.cc/paper/4312-generalizing-from-several-related-classification-tasks-to-a-new-unlabeled-sample"><strong>domain</strong></a> <a href="https://arxiv.org/abs/2007.01434"><strong>generalization</strong></a> do not directly assume access to data from the test distribution, but instead use data drawn from multiple training groups in order to learn a model that generalizes at test time to new groups (or new group distributions). So, these prior works have largely focused on the training procedure and generally do not adapt at test time (despite the name “domain adaptation”).</p>

<h2 id="combining-training-and-test-assumptions">Combining Training and Test Assumptions</h2>

<p>Prior frameworks for distribution shift have assumed either training groups or test batches, but we are not aware of any prior work that uses both assumptions. In our work, we demonstrate that it is precisely this conjunction that allows us to <em>learn to adapt</em> to test time distribution shift, by simulating both the shift and the adaptation procedure at training time. In this way, our framework can be understood as a <strong>meta-learning</strong> framework, and we refer interested readers to this <a href="https://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/">blog post</a> for a detailed overview of meta-learning.</p>

<h3 id="adaptive-risk-minimization">Adaptive Risk Minimization</h3>

<p>Our work proposes <a href="https://arxiv.org/abs/2007.02931">adaptive risk minimization</a>, or ARM, which is a problem setting and objective that makes use of both groups at training time and batches at test time. This synthesis provides a general and principled answer, through the lens of meta-learning, to the question of how to train for test time adaptation. In particular, we <em>meta-train</em> the model using simulated distribution shifts, which is enabled by the training groups, such that it exhibits strong <em>post-adaptation</em> performance on each shift. The model therefore directly learns how to best leverage the adaptation procedure, which it then executes in the exact same way at test time. If we can identify which test distribution shifts are likely, such as seeing data from new end users, then we can better construct simulated training shifts, such as sampling data from only one particular training user.</p>

<figure class="figure"><div class="figure__main">
<p><img width="100%" src="/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/arm.gif" /></p>
</div></figure>

<p>The training procedure for optimizing the ARM objective is illustrated in the graphic above. From the training data, we sample different batches that simulate different group distribution shifts. An <em>adaptation model</em> then has the opportunity to adapt the model parameters using the unlabeled examples. This allows us to meta-train the model for post-adaptation performance by directly performing gradient updates on both the model and the adaptation model.</p>

<figure class="figure"><div class="figure__main">
<p><img width="100%" src="/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/methods.png" /></p>
<figcaption>
We draw inspiration from contextual meta-learning (left) and gradient based meta-learning (right) in order to devise methods for ARM. For contextual meta-learning, we investigate two different methods that fall under this category. These methods are described in detail in <a href="https://arxiv.org/abs/2007.02931">our paper</a>.
</figcaption>
</div></figure>

<p>The connection to meta-learning is one key advantage of the ARM framework, as we are not starting from scratch when devising methods for solving ARM. In our work in particular, we draw inspiration from both <a href="https://arxiv.org/abs/1807.01613">contextual meta-learning</a> and <a href="https://arxiv.org/abs/1703.03400">gradient based meta-learning</a> to develop three methods for solving ARM, which we name ARM-CML, ARM-BN, and ARM-LL. We omit the details of these methods here, but they are illustrated in the figure above and described in full in <a href="https://arxiv.org/abs/2007.02931">our paper</a>.</p>

<p>The diversity of methods that we construct demonstrate the versatility and generality of the ARM problem formulation. But do we actually observe empirical gains using these methods? We investigate this question next.</p>

<h3 id="experiments">Experiments</h3>

<p>In our experiments, we first conducted a thorough study of the proposed ARM methods compared to various baselines, prior methods, and ablations, on four different image classification benchmarks exhibiting group distribution shift. <a href="https://arxiv.org/abs/2007.02931">Our paper</a> provides full details on the benchmarks and comparisons.</p>

<figure class="figure"><div class="figure__main">
<p><img width="100%" src="/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/results.png" /></p>
<figcaption>
We found that ARM methods empirically resulted in both better worst case (WC) and average (Avg) performance across groups compared to prior methods, indicating both better robustness and performance from the final trained models.
</figcaption>
</div></figure>

<p>In our main study, we found that ARM methods do better across the board both in terms of worst case and average test performance across groups, compared to a number of prior methods along with other baselines and ablations. The simplest method of ARM-BN, which can be implemented in just a few lines of additional code, often performed the best. This empirically shows the benefits of meta-learning, in that the model can be meta-trained to take greater advantage of the adaptation procedure.</p>

<figure class="figure"><div class="figure__main">
<p><img width="75%" src="/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/femnist.gif" /></p>
</div></figure>

<p>We also conducted some qualitative analyses, in which we investigated a test situation similar to the motivating example described at the beginning with a user that wrote double-storey a’s. We empirically found that models trained with ARM methods did in fact successfully adapt and predict “a” in this situation, when given enough examples of the user’s handwriting that included other “a”s and “2”s. Thus, this confirms our original hypothesis that training adaptive models is an effective way to deal with distribution shift.</p>

<p>We believe that the motivating example from the beginning as well as the empirical results in our paper convincingly argue for further study into general techniques for <em>adaptive models</em>. We have presented a general scheme for meta-training these models to better harness their adaptation capabilities, but a number of open questions remain, such as devising better adaptation procedures themselves. This broad research direction will be crucial for machine learning models to truly realize their potential in complex, real-world environments.</p>

<hr />

<p>Thanks to Chelsea Finn and Sergey Levine for providing valuable feedback on this post.
This blog post also appeared on the <a href="https://bair.berkeley.edu/blog/2020/11/05/arm/">Berkeley AI Research Blog</a>.</p>

<p>Part of this post is based on the following paper:</p>

<p>Marvin Zhang*, Henrik Marklund*, Nikita Dhawan*, Abhishek Gupta, Sergey Levine, Chelsea Finn.
<a href="https://arxiv.org/abs/2007.02931"><strong>Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift.</strong></a>
<a href="https://sites.google.com/view/adaptive-risk-minimization">Project webpage</a>
<a href="https://github.com/henrikmarklund/arm">Open source code</a></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>On the flip side, applicability to even pretrained models can be seen as a strength of these methods. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Alternatively referred to as domains, subpopulations, tasks, users, and more. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  
  </section>
  <hr>
  Keep on top of the latest SAIL Blog posts via <a class="social-icon" href="http://0.0.0.0:4000/blog/feed.xml">RSS <i class="fa fa-rss-square fa fa" title="Twitter"></i></a>, <a class="social-icon" href="https://twitter.com/StanfordAILab">Twitter <i class="fa fa-twitter-square fa fa" title="Twitter"></i></a>, or email:

<!-- Begin Mailchimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="https://stanford.us19.list-manage.com/subscribe/post?u=3a6484754abf2fc18724ec835&amp;id=028823e92b" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_3a6484754abf2fc18724ec835_028823e92b" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->



  <!-- Social media shares -->
  <div class="share-buttons">
    <ul class="share-buttons">
        <div class="meta">Share</div>
        
        <li>
            <a href="https://www.facebook.com/sharer/sharer.php?u=http://0.0.0.0:4000/blog/adaptive-risk-minimization/" target="_blank" title="Share on Facebook">
			<i class="fa fa-facebook-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Facebook</span>
		</a>
        </li>
         
        <li>
            <a href="https://twitter.com/intent/tweet?source=http://0.0.0.0:4000/blog/adaptive-risk-minimization/&text=Adapting+on+the+Fly+to+Test+Time+Distribution+Shift%20%7C%20SAIL+Blog:%20http://0.0.0.0:4000/blog/adaptive-risk-minimization/" target="_blank" title="Tweet">
			<i class="fa fa-twitter-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Tweet</span>
		</a>
        </li>
            
        <li>
            <a href="https://getpocket.com/save?url=http://0.0.0.0:4000/blog/adaptive-risk-minimization/&title=Adapting+on+the+Fly+to+Test+Time+Distribution+Shift%20%7C%20SAIL+Blog" target="_blank" title="Add to Pocket">
			<i class="fa fa fa-get-pocket fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Add to Pocket</span>
		</a>
        </li>
         
        <li>
            <a href="http://www.reddit.com/submit?url=http://0.0.0.0:4000/blog/adaptive-risk-minimization/&title=Adapting+on+the+Fly+to+Test+Time+Distribution+Shift%20%7C%20SAIL+Blog" target="_blank" title="Share on Reddit">
			<i class="fa fa-reddit-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Reddit</span>
		</a>
        </li>
           
        <li>
            <a href="mailto:?subject=Adapting+on+the+Fly+to+Test+Time+Distribution+Shift%20%7C%20SAIL+Blog&body=:%20http://0.0.0.0:4000/blog/adaptive-risk-minimization/" target="_blank" title="Email">
			<i class="fa fa-envelope-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Email</span>
		</a>
        </li>
        
    </ul>
</div>

  <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/blog/tags#meta-learning">
      <p><i class="fa fa-tag fa-fw"></i> meta-learning</p>
    </a>
    
    <a class="button" href="/blog/tags#ml">
      <p><i class="fa fa-tag fa-fw"></i> ml</p>
    </a>
    
  </div>
</footer>

</article>

<!-- Disqus -->


<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <a href="/blog/mlsys/">
      <p>Previous post</p>
        The Coming Wave of ML Systems
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <a href="/blog/DrRepair/">
      <p>Next post</p>
        Learning to Fix Programs from Error Messages
      </a>
  </div>
  
</div>



    </div>
    <hr>
<footer class="site-footer">
    
   <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        
<li>
	<a href="http://0.0.0.0:4000/blog/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>







































<li>
	<a href="https://twitter.com/StanfordAILab" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








        </ul>
    </div>
    <p class="text">&copy; 2019 Stanford AI Lab
</p>
 
</footer>



  </body>
</html>
