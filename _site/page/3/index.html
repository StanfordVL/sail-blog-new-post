<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/blog/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">

    <!--Favicon-->
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-16x16.png" sizes="16x16" />

    <!-- Canonical -->
    <link rel="canonical" href="http://0.0.0.0:4000/blog/page/3/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="The Stanford AI Lab Blog" href="http://0.0.0.0:4000/blog/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/font-awesome.min.css">
    
    <!-- Bootstrap-3.3.7 isolation CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">


    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    
    <!-- JQuery 2.2.4 -->
    <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/bigfoot-number.css">
    <script type="text/javascript" src="/blog/assets/js/vendor/bigfoot.min.js"></script>
    <script type="text/javascript">
    $(document).ready(function() { 
      $.bigfoot();
      
    window.onload = function() {

        var videos = document.getElementsByTagName("video"),
            fraction = 0.8;

        function checkScroll() {

            for (var i = 0; i < videos.length; i++) {

                var video = videos[i];

                var x = video.offsetLeft,
                    y = video.offsetTop,
                    w = video.offsetWidth,
                    h = video.offsetHeight,
                    r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }

        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    }
    }); 
    </script>
    


    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/katex.min.css">
    <script src="/blog/assets/js/vendor/katex.min.js">
    </script>
    
    
    
    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-129018108-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Page 3 of 6 for All Posts - Page 3 | SAIL Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="All Posts - Page 3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The official Stanford AI Lab blog" />
<meta property="og:description" content="The official Stanford AI Lab blog" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/page/3/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/page/3/" />
<meta property="og:site_name" content="SAIL Blog" />
<link rel="prev" href="http://0.0.0.0:4000/blog/page/2/index.html" />
<link rel="next" href="http://0.0.0.0:4000/blog/page/4/index.html" />
<script type="application/ld+json">
{"description":"The official Stanford AI Lab blog","@type":"WebPage","url":"http://0.0.0.0:4000/blog/page/3/","headline":"All Posts - Page 3","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    
    <!-- Manual seo tags -->
    <title>All Posts - Page 3 | The Stanford AI Lab Blog</title>
    <meta name="description" content="The Stanford AI Lab (SAIL) Blog is a place for SAIL students, faculty, and researchers to share our work with the general public.">
    
    <!-- Twitter Cards -->
    <meta name="twitter:title" content="All Posts - Page 3">
    
    <meta name="twitter:description" content="The Stanford AI Lab (SAIL) Blog is a place for SAIL students, faculty, and researchers to share our work with the general public.">
    
    <meta name="twitter:creator" content="@StanfordAILab">
     
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="http://0.0.0.0:4000/blog/assets/img/sail-logo.png">
    <meta name="og:image" content="http://0.0.0.0:4000/blog/assets/img/sail-logo.png">
    
</head>

  <body class="category_posts-body">
      <!-- Toggle menu -->
<header class="site-header">

<nav class="clear navbar navbar-expand-lg navbar-light bg-white flex-column flex-md-row bd-navbar fixed-top" id="main_nav">
  
  <div class="container">

    <a class="navbar-brand mr-0 mr-md-2 text-black d-flex align-items-center" href="/blog/" aria-label="Bootstrap">
    
	  <div class="branding">
	    <a href="http://ai.stanford.edu/">
	      <img class="avatar" src="/blog/assets/img/sail-logo.png" alt=""/>
		  </a>

      <a href="/blog/">
	      <h1 class="site-title">
			    The Stanford AI Lab Blog
		    </h1> 
		  </a>
	  </div>
    
    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse" id="navbarResponsive">

      <ul class="navbar-nav ml-auto">
      
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/about">About</a>
      </li>
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
        <div class="dropdown-menu">
        <a class="dropdown-item" href="/blog/">All</a>
        <a class="dropdown-item" href="/blog/conferences">Conferences</a>
        <a class="dropdown-item" href="/blog/vision">Computer Vision</a>
        <a class="dropdown-item" href="/blog/robotics">Robotics</a>
        <a class="dropdown-item" href="/blog/nlp">NLP</a>
        <a class="dropdown-item" href="/blog/ml">Machine Learning</a>
        <a class="dropdown-item" href="/blog/rl">Reinforcement Learning</a>

        </div>
      </li>
        
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/subscribe">Subscribe</a>
      </li>
      
      
      <li class="nav-item">
      <a class="nav-link" href="http://ai.stanford.edu/">SAIL</a>
      </li>
      
      </ul> 

    </div>

  </div>
</nav>

</header>

  
    <div class="content">
      <div class="home">
  <div class="posts">
  <br>
    <header id="main">
  <h1 id="All+Posts+-+Page+3" class="title">
      All Posts - Page 3
  </h1>
  
  
  <hr>
</header>

    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-06-25-trajectory-forecasting/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/trajectory-forecasting/">
              <h2> Back to the Future: Planning-Aware Trajectory Forecasting for Autonomous Driving </h2>
            </a>

             <p class="meta">
              <a href="http://www.borisivanovic.com">Boris Ivanovic</a>
              <!-- June 25, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Recent advances in deep generative modeling have brought forth a paradigm shift in trajectory forecasting. In this blog post, we provide an overview of existing work, highlight new opportunities, and present our latest work on developing methods that are cognizant of their downstream use cases.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/trajectory-forecasting/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-06-15-cvpr-2020/logo_small.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/cvpr-2020/">
              <h2> Stanford AI Lab Papers and Talks at CVPR 2020 </h2>
            </a>

             <p class="meta">
              Compiled by <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>
              <!-- June 15, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  All the great work from the Stanford AI Lab accepted at CVPR 2020, all in one place.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/cvpr-2020/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-05-30-icra-2020/logo.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/icra-2020/">
              <h2> SAIL and Stanford Robotics at ICRA 2020 </h2>
            </a>

             <p class="meta">
              Compiled by <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>
              <!-- May 30, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  All the great work from the Stanford AI Lab accepted at ICRA 2020, all in one place.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/icra-2020/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-05-26-finding-crosslingual-syntax/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/finding-crosslingual-syntax/">
              <h2> Finding Cross-Lingual Syntax in Multilingual BERT </h2>
            </a>

             <p class="meta">
              <a href="http://ethanachi.com">Ethan A. Chi</a>
              <!-- May 26, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Large neural language models such as BERT have seen surprising success with multilingual pre-training on a large number of languages. We demonstrate that Multilingual BERT learns cross-lingual syntax, visualizing its inherent structure.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/finding-crosslingual-syntax/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-05-18-selfsupervised-multimodal/intro.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/selfsupervised-multimodal/">
              <h2> Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks  </h2>
            </a>

             <p class="meta">
              <a href="http://stanford.edu/~mishlee/">Michelle A. Lee</a>
              <!-- May 18, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Contact-rich manipulation tasks in unstructured environments often require both tactile and visual feedback. In this blog post, we introduce how to use self-supervision to learn a compact and multimodal representation of vision and touch.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/selfsupervised-multimodal/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-05-06-ntp-ntg/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/ntp-ntg/">
              <h2> Leveraging Compositionality for One-Shot Imitation Learning </h2>
            </a>

             <p class="meta">
              <a href="http://ai.stanford.edu/~dahuang/">De-An Huang</a>, <a href="https://cs.stanford.edu/~danfei/">Danfei Xu</a>
              <!-- May 6, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We introduce a class of algorithms that solve long-horizon one-shot imitation learning by leveraging compositional priors.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/ntp-ntg/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-04-27-iclr/logo.jpg">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/iclr-2020/">
              <h2> SAIL at ICLR 2020: Accepted Papers and Videos </h2>
            </a>

             <p class="meta">
              Compiled by <a href='https://twitter.com/SharonYixuanLi'>Sharon Li</a>, <a href='https://twitter.com/krandiash'>Karan Goel</a> and <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>
              <!-- April 27, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  All the great work from the Stanford AI Lab accepted at ICLR 2020, in one place.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/iclr-2020/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-04-20-data-augmentation/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/data-augmentation/">
              <h2> Automating Data Augmentation: Practice, Theory and New Direction </h2>
            </a>

             <p class="meta">
              <a href='http://yixuanli.net/'>Sharon Y. Li</a>
              <!-- April 24, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Data augmentation is a de facto technique used in nearly every state-of-the-art machine learning model. In this blog post, we provide an overview of recent work on the practice, theory and new direction of data augmentation research.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/data-augmentation/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-04-08-cavin/pull_figure.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/cavin/">
              <h2> Sequential Problem Solving by Hierarchical Planning in Latent Spaces </h2>
            </a>

             <p class="meta">
              <a href='http://ai.stanford.edu/~kuanfang/'>Kuan Fang</a>
              <!-- April 10, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We propose a hierarchical planning algorithm in learned latent spaces. Our method uses deep generative models to prioritize promising actions for sampling-based planning.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/cavin/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-03-24-contextual/teaser.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/contextual/">
              <h2> BERT, ELMo, & GPT-2: How Contextual are Contextualized Word Representations? </h2>
            </a>

             <p class="meta">
              <a href='https://kawine.github.io/'>Kawin Ethayarajh</a>
              <!-- March 24, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Replacing static vectors with contextualized word representations has led to significant improvements on virtually every NLP task. In this blog post we study the geometric properties of contextualized word representations and find surprising conclusions.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/contextual/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
  </div>

  
  <div class="paginate pager">

      
          <a href="/blog/page/2/index.html" class="button" >
          <i class="fa fa-chevron-left"></i>
          Prev
          </a>
      

      
          <a href="/blog/page/4/index.html" class="button" >
          Next
          <i class="fa fa-chevron-right"></i>
          </a>
      

  </div>
  

</div>


    </div>
    <hr>
<footer class="site-footer">
    
   <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        
<li>
	<a href="http://0.0.0.0:4000/blog/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>







































<li>
	<a href="https://twitter.com/StanfordAILab" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








        </ul>
    </div>
    <p class="text">&copy; 2019 Stanford AI Lab
</p>
 
</footer>



  </body>
</html>
