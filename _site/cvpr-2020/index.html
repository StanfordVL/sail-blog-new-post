<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/blog/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">

    <!--Favicon-->
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-16x16.png" sizes="16x16" />

    <!-- Canonical -->
    <link rel="canonical" href="http://0.0.0.0:4000/blog/cvpr-2020/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="The Stanford AI Lab Blog" href="http://0.0.0.0:4000/blog/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/font-awesome.min.css">
    
    <!-- Bootstrap-3.3.7 isolation CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">


    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    
    <!-- JQuery 2.2.4 -->
    <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/bigfoot-number.css">
    <script type="text/javascript" src="/blog/assets/js/vendor/bigfoot.min.js"></script>
    <script type="text/javascript">
    $(document).ready(function() { 
      $.bigfoot();
      
    window.onload = function() {

        var videos = document.getElementsByTagName("video"),
            fraction = 0.8;

        function checkScroll() {

            for (var i = 0; i < videos.length; i++) {

                var video = videos[i];

                var x = video.offsetLeft,
                    y = video.offsetTop,
                    w = video.offsetWidth,
                    h = video.offsetHeight,
                    r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }

        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    }
    }); 
    </script>
    


    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/katex.min.css">
    <script src="/blog/assets/js/vendor/katex.min.js">
    </script>
    
    
    
    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-129018108-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Stanford AI Lab Papers and Talks at CVPR 2020 | SAIL Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Stanford AI Lab Papers and Talks at CVPR 2020" />
<meta name="author" content="Compiled by <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The official Stanford AI Lab blog" />
<meta property="og:description" content="The official Stanford AI Lab blog" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/cvpr-2020/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/cvpr-2020/" />
<meta property="og:site_name" content="SAIL Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-15T00:00:00-07:00" />
<script type="application/ld+json">
{"description":"The official Stanford AI Lab blog","author":{"@type":"Person","name":"Compiled by <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>"},"@type":"BlogPosting","url":"http://0.0.0.0:4000/blog/cvpr-2020/","headline":"Stanford AI Lab Papers and Talks at CVPR 2020","dateModified":"2020-06-15T00:00:00-07:00","datePublished":"2020-06-15T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/blog/cvpr-2020/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    
    <!-- Manual seo tags -->
    <title>Stanford AI Lab Papers and Talks at CVPR 2020 | The Stanford AI Lab Blog</title>
    <meta name="description" content="All the great work from the Stanford AI Lab accepted at CVPR 2020, all in one place.">
    
    <!-- Twitter Cards -->
    <meta name="twitter:title" content="Stanford AI Lab Papers and Talks at CVPR 2020">
    
    <meta name="twitter:description" content="All the great work from the Stanford AI Lab accepted at CVPR 2020, all in one place.">
    
    <meta name="twitter:creator" content="@StanfordAILab">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://0.0.0.0:4000/blog/assets/img/posts/2020-06-15-cvpr-2020/logo_small.png">
    <meta name="og:image" content="http://0.0.0.0:4000/blog/assets/img/posts/2020-06-15-cvpr-2020/logo_small.png">
    
</head>

  <body class="post-body">
      <!-- Toggle menu -->
<header class="site-header">

<nav class="clear navbar navbar-expand-lg navbar-light bg-white flex-column flex-md-row bd-navbar fixed-top" id="main_nav">
  
  <div class="container">

    <a class="navbar-brand mr-0 mr-md-2 text-black d-flex align-items-center" href="/blog/" aria-label="Bootstrap">
    
	  <div class="branding">
	    <a href="http://ai.stanford.edu/">
	      <img class="avatar" src="/blog/assets/img/sail-logo.png" alt=""/>
		  </a>

      <a href="/blog/">
	      <h1 class="site-title">
			    The Stanford AI Lab Blog
		    </h1> 
		  </a>
	  </div>
    
    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse" id="navbarResponsive">

      <ul class="navbar-nav ml-auto">
      
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/about">About</a>
      </li>
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
        <div class="dropdown-menu">
        <a class="dropdown-item" href="/blog/">All</a>
        <a class="dropdown-item" href="/blog/conferences">Conferences</a>
        <a class="dropdown-item" href="/blog/vision">Computer Vision</a>
        <a class="dropdown-item" href="/blog/robotics">Robotics</a>
        <a class="dropdown-item" href="/blog/nlp">NLP</a>
        <a class="dropdown-item" href="/blog/ml">Machine Learning</a>
        <a class="dropdown-item" href="/blog/rl">Reinforcement Learning</a>

        </div>
      </li>
        
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/subscribe">Subscribe</a>
      </li>
      
      
      <li class="nav-item">
      <a class="nav-link" href="http://ai.stanford.edu/">SAIL</a>
      </li>
      
      </ul> 

    </div>

  </div>
</nav>

</header>

  
    <div class="content">
      

<article>

  <header id="main">
    
    <h1 id="post_title">Stanford AI Lab Papers and Talks at CVPR 2020</h1>
    <p class="meta">
    Compiled by <a href='https://twitter.com/andrey_kurenkov'>Andrey Kurenkov</a>
    <div class="post-date">June 15, 2020</div>
    </p>
  <hr>
  </header>


  <section class="post-content">
  
    <p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/logo.png" /></p>

<p>The <a href="http://cvpr2020.thecvf.com/">Conference on Computer Vision and Pattern Recognition</a> (CVPR) 2020 is being hosted virtually from June 14th - June 19th. We’re excited to share all the work from SAIL that’s being presented, and you’ll find links to papers, videos and blogs below. Feel free to reach out to the contact authors directly to learn more about the work that’s happening at Stanford!</p>

<h2 id="list-of-accepted-papers">List of Accepted Papers</h2>
<h4 id="action-genome-actions-as-compositions-of-spatio-temporal-scene-graphs"><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Action_Genome_Actions_As_Compositions_of_Spatio-Temporal_Scene_Graphs_CVPR_2020_paper.pdf">Action Genome: Actions as Compositions of Spatio-temporal Scene Graphs</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img13" />
<strong>Authors</strong>: Jingwei Ji, Ranjay Krishna, Li Fei-Fei, Juan Carlos Niebles
<br /><strong>Contact</strong>: jingweij@cs.stanford.edu
<br /><strong>Links:</strong> <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Action_Genome_Actions_As_Compositions_of_Spatio-Temporal_Scene_Graphs_CVPR_2020_paper.pdf">Paper</a>
<br /><strong>Keywords</strong>: action recognition, scene graph, video understanding, relationships, composition, action, activity, video</p>
<hr />

<h4 id="adacoseg-adaptive-shape-co-segmentation-with-group-consistency-loss"><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_AdaCoSeg_Adaptive_Shape_Co-Segmentation_With_Group_Consistency_Loss_CVPR_2020_paper.pdf">AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img11" />
<strong>Authors</strong>: Chenyang Zhu, Kai Xu, Siddhartha Chaudhuri, Li Yi, Leonidas J. Guibas, Hao Zhang
<br /><strong>Contact</strong>: guibas@cs.stanford.edu
<br /><strong>Links:</strong> <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_AdaCoSeg_Adaptive_Shape_Co-Segmentation_With_Group_Consistency_Loss_CVPR_2020_paper.pdf">Paper</a>
<br /><strong>Keywords</strong>: shape segmentation, consistency</p>
<hr />

<h4 id="adversarial-texture-optimization-from-rgb-d-scans"><a href="http://stanford.edu/~jingweih/papers/advtex/supp/paper.pdf">Adversarial Texture Optimization from RGB-D Scans</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img12" />
<strong>Authors</strong>: Jingwei Huang, Justus Thies, Angela Dai, Abhijit Kundu, Chiyu Jiang, Leonidas Guibas, Matthias Nießner, Thomas Funkhouser
<br /><strong>Contact</strong>: jingweih@stanford,edu
<br /><strong>Links:</strong> <a href="http://stanford.edu/~jingweih/papers/advtex/supp/paper.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=52xlRn0ESek&amp;feature=youtu.be">Video</a>
<br /><strong>Keywords</strong>: texture; adversarial;</p>
<hr />

<h4 id="bodies-at-rest-3d-human-pose-and-shape-estimation-from-a-pressure-image-using-synthetic-data"><a href="https://arxiv.org/pdf/2004.01166.pdf">Bodies at Rest: 3D Human Pose and Shape Estimation from a Pressure Image using Synthetic Data</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img8" />
<strong>Authors</strong>: Henry M. Clever, Zackory Erickson, Ari Kapusta, Greg Turk, C.Karen Liu, and Charlie C. Kemp
<br /><strong>Contact</strong>: karenliu@cs.stanford.edu
<br /><strong>Links:</strong> <a href="https://arxiv.org/pdf/2004.01166.pdf">Paper</a> | <a href="https://youtu.be/Y7-2D5TwRJY">Video</a>
<br /><strong>Keywords</strong>: human pose estimation;</p>
<hr />

<h4 id="category-level-articulated-object-pose-estimation"><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Category-Level_Articulated_Object_Pose_Estimation_CVPR_2020_paper.pdf">Category-Level Articulated Object Pose Estimation</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img5" />
<strong>Authors</strong>: Xiaolong Li, He Wang, Li Yi, Leonidas Guibas, A. Lynn Abbott, Shuran Song
<br /><strong>Contact</strong>: hewang@stanford.edu
<br /><strong>Award nominations:</strong> Oral presentation
<br /><strong>Links:</strong> <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Category-Level_Articulated_Object_Pose_Estimation_CVPR_2020_paper.pdf">Paper</a> | <a href="https://youtu.be/S8Amc6D8SKY">Video</a>
<br /><strong>Keywords</strong>: category level pose estimation, articulated object, 3d vision, point cloud, object part, object joint, segmentation, kinematic constraints</p>
<hr />

<h4 id="few-shot-video-classification-via-temporal-alignment"><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_Few-Shot_Video_Classification_via_Temporal_Alignment_CVPR_2020_paper.pdf">Few-Shot Video Classification via Temporal Alignment</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img9" />
<strong>Authors</strong>: Kaidi Cao, Jingwei Ji<em>, Zhangjie Cao</em>, Chien-Yi Chang, Juan Carlos Niebles
<br /><strong>Contact</strong>: kaidicao@cs.stanford.edu
<br /><strong>Links:</strong> <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Cao_Few-Shot_Video_Classification_via_Temporal_Alignment_CVPR_2020_paper.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=ddLBzFzRcOo">Video</a>
<br /><strong>Keywords</strong>: video classification, few-shot learning, action recognition, temporal alignment</p>
<hr />

<h4 id="imvotenet-boosting-3d-object-detection-in-point-clouds-with-image-votes"><a href="https://arxiv.org/abs/2001.10692">ImVoteNet: Boosting 3D Object Detection in Point Clouds With Image Votes</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img7" />
<strong>Authors</strong>: Charles R. Qi, Xinlei Chen, Or Litany, Leonidas J. Guibas
<br /><strong>Contact</strong>: or.litany@gmail.com
<br /><strong>Links:</strong> <a href="https://arxiv.org/abs/2001.10692">Paper</a>
<br /><strong>Keywords</strong>: 3d object detection, rgb-d, voting, point clouds, multi-modality, fusion, deep learning, object recognition.</p>
<hr />

<h4 id="learning-multiview-3d-point-cloud-registration"><a href="https://arxiv.org/pdf/2001.05119.pdf">Learning multiview 3D point cloud registration</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img4" />
<strong>Authors</strong>: Zan Gojcic, Caifa Zhou, Jan D. Wegner, Leonidas J. Guibas, Tolga Birdal
<br /><strong>Contact</strong>: tbirdal@stanford.edu
<br /><strong>Links:</strong> <a href="https://arxiv.org/pdf/2001.05119.pdf">Paper</a> | <a href="https://youtu.be/Girxxvv8joQ">Video</a>
<br /><strong>Keywords</strong>: registration, multiview, 3d reconstruction, point clouds, global alignment, synchronization, 3d, local features, end to end, 3d matching</p>
<hr />

<h4 id="robust-learning-through-cross-task-consistency-"><a href="https://consistency.epfl.ch/Cross_Task_Consistency_CVPR2020.pdf">Robust Learning Through Cross-Task Consistency </a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img10" />
<strong>Authors</strong>: Amir R. Zamir, Alexander Sax, Nikhil Cheerla, Rohan Suri, Zhangjie Cao, Jitendra Malik, Leonidas J. Guibas;
<br /><strong>Contact</strong>: guibas@cs.stanford.edu
<br /><strong>Links:</strong> <a href="https://consistency.epfl.ch/Cross_Task_Consistency_CVPR2020.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=dPzQusIjkQU">Video</a>
<br /><strong>Keywords</strong>: multi-task learning, transfer learning, cycle consistency</p>
<hr />

<h4 id="sapien-a-simulated-part-based-interactive-environment"><a href="https://arxiv.org/abs/2003.08515">SAPIEN: A SimulAted Part-based Interactive ENvironment</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img2" />
<strong>Authors</strong>: Fanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia, Hao Zhu, Fangchen Liu, Minghua Liu, Hanxiao Jiang, Yifu Yuan, He Wang, Li Yi, Angel X.Chang, Leonidas J. Guibas, Hao Su
<br /><strong>Contact</strong>: kaichunm@stanford.edu
<br /><strong>Award nominations:</strong> Oral presentation
<br /><strong>Links:</strong> <a href="https://arxiv.org/abs/2003.08515">Paper</a> | <a href="https://www.youtube.com/watch?v=K2yOeJhJXzM">Video</a>
<br /><strong>Keywords</strong>: robotic simulator, 3d shape parts, robotic manipulation, 3d vision and robotics</p>
<hr />

<h4 id="spatio-temporal-graph-for-video-captioning-with-knowledge-distillation"><a href="https://arxiv.org/abs/2003.13942">Spatio-Temporal Graph for Video Captioning with Knowledge Distillation</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img3" />
<strong>Authors</strong>: Boxiao Pan, Haoye Cai, De-An Huang, Kuan-Hui Lee, Adrien Gaidon, Ehsan Adeli, Juan Carlos Niebles
<br /><strong>Contact</strong>: bxpan@stanford.edu
<br /><strong>Links:</strong> <a href="https://arxiv.org/abs/2003.13942">Paper</a> | <a href="https://youtu.be/QxHttaZF_Xc">Video</a>
<br /><strong>Keywords</strong>: video captioning, spatio-temporal graph, knowledge distillation, video understanding, vision and language.</p>
<hr />

<h4 id="structedit-learning-structural-shape-variations"><a href="https://arxiv.org/abs/1911.11098">StructEdit: Learning Structural Shape Variations</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img1" />
<strong>Authors</strong>: Kaichun Mo<em>, Paul Guerrero</em>, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, Leonidas J. Guibas
<br /><strong>Contact</strong>: kaichunm@stanford.edu
<br /><strong>Links:</strong> <a href="https://arxiv.org/abs/1911.11098">Paper</a>
<br /><strong>Keywords</strong>: shape editing; shape structure; 3d vision and graphics</p>
<hr />

<h4 id="synchronizing-probability-measures-on-rotations-via-optimal-transport"><a href="https://arxiv.org/pdf/2004.00663.pdf">Synchronizing Probability Measures on Rotations via Optimal Transport</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img0" />
<strong>Authors</strong>: Tolga Birdal, Michael Arbel, Umut Şimşekli, Leonidas Guibas
<br /><strong>Contact</strong>: tbirdal@stanford.edu
<br /><strong>Links:</strong> <a href="https://arxiv.org/pdf/2004.00663.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=yiy83nlexls">Video</a>
<br /><strong>Keywords</strong>: synchronization, optimal transport, rotation averaging, slam, sfm, probability measure, riemannian, gradient descent, pose estimation</p>
<hr />

<h4 id="unsupervised-learning-from-video-with-deep-neural-embeddings"><a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Zhuang_Unsupervised_Learning_From_Video_With_Deep_Neural_Embeddings_CVPR_2020_paper.html">Unsupervised Learning From Video With Deep Neural Embeddings</a></h4>
<p><img class="postimage_75" src="/blog/assets/img/posts/2020-06-15-cvpr-2020/img6" />
<strong>Authors</strong>: Chengxu Zhuang, Tianwei She, Alex Andonian, Max Sobol Mark, Daniel Yamins
<br /><strong>Contact</strong>: chengxuz@stanford.edu
<br /><strong>Links:</strong> <a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Zhuang_Unsupervised_Learning_From_Video_With_Deep_Neural_Embeddings_CVPR_2020_paper.html">Paper</a>
<br /><strong>Keywords</strong>: unsupervised learning, self-supervised learning, video learning, contrastive learning, deep neural networks, action recognition, object recognition, two-pathway models</p>

<hr />

<p>We look forward to seeing you at CVPR!</p>

  
  </section>
  <hr>
  Keep on top of the latest SAIL Blog posts via <a class="social-icon" href="http://0.0.0.0:4000/blog/feed.xml">RSS <i class="fa fa-rss-square fa fa" title="Twitter"></i></a>, <a class="social-icon" href="https://twitter.com/StanfordAILab">Twitter <i class="fa fa-twitter-square fa fa" title="Twitter"></i></a>, or email:

<!-- Begin Mailchimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="https://stanford.us19.list-manage.com/subscribe/post?u=3a6484754abf2fc18724ec835&amp;id=028823e92b" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_3a6484754abf2fc18724ec835_028823e92b" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->



  <!-- Social media shares -->
  <div class="share-buttons">
    <ul class="share-buttons">
        <div class="meta">Share</div>
        
        <li>
            <a href="https://www.facebook.com/sharer/sharer.php?u=http://0.0.0.0:4000/blog/cvpr-2020/" target="_blank" title="Share on Facebook">
			<i class="fa fa-facebook-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Facebook</span>
		</a>
        </li>
         
        <li>
            <a href="https://twitter.com/intent/tweet?source=http://0.0.0.0:4000/blog/cvpr-2020/&text=Stanford+AI+Lab+Papers+and+Talks+at+CVPR+2020%20%7C%20SAIL+Blog:%20http://0.0.0.0:4000/blog/cvpr-2020/" target="_blank" title="Tweet">
			<i class="fa fa-twitter-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Tweet</span>
		</a>
        </li>
            
        <li>
            <a href="https://getpocket.com/save?url=http://0.0.0.0:4000/blog/cvpr-2020/&title=Stanford+AI+Lab+Papers+and+Talks+at+CVPR+2020%20%7C%20SAIL+Blog" target="_blank" title="Add to Pocket">
			<i class="fa fa fa-get-pocket fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Add to Pocket</span>
		</a>
        </li>
         
        <li>
            <a href="http://www.reddit.com/submit?url=http://0.0.0.0:4000/blog/cvpr-2020/&title=Stanford+AI+Lab+Papers+and+Talks+at+CVPR+2020%20%7C%20SAIL+Blog" target="_blank" title="Share on Reddit">
			<i class="fa fa-reddit-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Reddit</span>
		</a>
        </li>
           
        <li>
            <a href="mailto:?subject=Stanford+AI+Lab+Papers+and+Talks+at+CVPR+2020%20%7C%20SAIL+Blog&body=:%20http://0.0.0.0:4000/blog/cvpr-2020/" target="_blank" title="Email">
			<i class="fa fa-envelope-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Email</span>
		</a>
        </li>
        
    </ul>
</div>

  <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/blog/tags#CVPR">
      <p><i class="fa fa-tag fa-fw"></i> CVPR</p>
    </a>
    
    <a class="button" href="/blog/tags#conference">
      <p><i class="fa fa-tag fa-fw"></i> conference</p>
    </a>
    
    <a class="button" href="/blog/tags#publication">
      <p><i class="fa fa-tag fa-fw"></i> publication</p>
    </a>
    
    <a class="button" href="/blog/tags#video">
      <p><i class="fa fa-tag fa-fw"></i> video</p>
    </a>
    
    <a class="button" href="/blog/tags#vision">
      <p><i class="fa fa-tag fa-fw"></i> vision</p>
    </a>
    
  </div>
</footer>

</article>

<!-- Disqus -->


<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <a href="/blog/icra-2020/">
      <p>Previous post</p>
        SAIL and Stanford Robotics at ICRA 2020
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <a href="/blog/trajectory-forecasting/">
      <p>Next post</p>
        Back to the Future: Planning-Aware Trajectory Forecasting for Autonomous Driving
      </a>
  </div>
  
</div>



    </div>
    <hr>
<footer class="site-footer">
    
   <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        
<li>
	<a href="http://0.0.0.0:4000/blog/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>







































<li>
	<a href="https://twitter.com/StanfordAILab" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








        </ul>
    </div>
    <p class="text">&copy; 2019 Stanford AI Lab
</p>
 
</footer>



  </body>
</html>
