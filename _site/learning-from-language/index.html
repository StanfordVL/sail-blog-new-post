<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/blog/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">

    <!--Favicon-->
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-16x16.png" sizes="16x16" />

    <!-- Canonical -->
    <link rel="canonical" href="http://0.0.0.0:4000/blog/learning-from-language/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="The Stanford AI Lab Blog" href="http://0.0.0.0:4000/blog/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/font-awesome.min.css">
    
    <!-- Bootstrap-3.3.7 isolation CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">


    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    
    <!-- JQuery 2.2.4 -->
    <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/bigfoot-number.css">
    <script type="text/javascript" src="/blog/assets/js/vendor/bigfoot.min.js"></script>
    <script type="text/javascript">
    $(document).ready(function() { 
      $.bigfoot();
      
    window.onload = function() {

        var videos = document.getElementsByTagName("video"),
            fraction = 0.8;

        function checkScroll() {

            for (var i = 0; i < videos.length; i++) {

                var video = videos[i];

                var x = video.offsetLeft,
                    y = video.offsetTop,
                    w = video.offsetWidth,
                    h = video.offsetHeight,
                    r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }

        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    }
    }); 
    </script>
    


    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/katex.min.css">
    <script src="/blog/assets/js/vendor/katex.min.js">
    </script>
    
    
    
    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-129018108-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Learning from Language Explanations | SAIL Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Learning from Language Explanations" />
<meta name="author" content="<a href="https://cs.stanford.edu/~muj/">Jesse Mu</a> and <a href="https://murtyshikhar.github.io/">Shikhar Murty</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Imagine you’re a machine learning practitioner and you want to solve some classification problem, like classifying groups of colored squares as being either 1s or 0s. Here’s what you would typically do: collect a large dataset of examples, label the data, and train a classifier:" />
<meta property="og:description" content="Imagine you’re a machine learning practitioner and you want to solve some classification problem, like classifying groups of colored squares as being either 1s or 0s. Here’s what you would typically do: collect a large dataset of examples, label the data, and train a classifier:" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/learning-from-language/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/learning-from-language/" />
<meta property="og:site_name" content="SAIL Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-23T00:00:00-08:00" />
<script type="application/ld+json">
{"description":"Imagine you’re a machine learning practitioner and you want to solve some classification problem, like classifying groups of colored squares as being either 1s or 0s. Here’s what you would typically do: collect a large dataset of examples, label the data, and train a classifier:","author":{"@type":"Person","name":"<a href=\"https://cs.stanford.edu/~muj/\">Jesse Mu</a> and <a href=\"https://murtyshikhar.github.io/\">Shikhar Murty</a>"},"@type":"BlogPosting","url":"http://0.0.0.0:4000/blog/learning-from-language/","headline":"Learning from Language Explanations","dateModified":"2020-11-23T00:00:00-08:00","datePublished":"2020-11-23T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://0.0.0.0:4000/blog/learning-from-language/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    
    <!-- Manual seo tags -->
    <title>Learning from Language Explanations | The Stanford AI Lab Blog</title>
    <meta name="description" content="Language is a crucial way for humans to teach other humans. Can we use language to teach machines?">
    
    <!-- Twitter Cards -->
    <meta name="twitter:title" content="Learning from Language Explanations">
    
    <meta name="twitter:description" content="Language is a crucial way for humans to teach other humans. Can we use language to teach machines?">
    
    <meta name="twitter:creator" content="@StanfordAILab">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://0.0.0.0:4000/blog//assets/img/posts/2020-11-23-learning-from-language/thumb.jpg">
    <meta name="og:image" content="http://0.0.0.0:4000/blog//assets/img/posts/2020-11-23-learning-from-language/thumb.jpg">
    
</head>

  <body class="post-body">
      <!-- Toggle menu -->
<header class="site-header">

<nav class="clear navbar navbar-expand-lg navbar-light bg-white flex-column flex-md-row bd-navbar fixed-top" id="main_nav">
  
  <div class="container">

    <a class="navbar-brand mr-0 mr-md-2 text-black d-flex align-items-center" href="/blog/" aria-label="Bootstrap">
    
	  <div class="branding">
	    <a href="http://ai.stanford.edu/">
	      <img class="avatar" src="/blog/assets/img/sail-logo.png" alt=""/>
		  </a>

      <a href="/blog/">
	      <h1 class="site-title">
			    The Stanford AI Lab Blog
		    </h1> 
		  </a>
	  </div>
    
    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse" id="navbarResponsive">

      <ul class="navbar-nav ml-auto">
      
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/about">About</a>
      </li>
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
        <div class="dropdown-menu">
        <a class="dropdown-item" href="/blog/">All</a>
        <a class="dropdown-item" href="/blog/conferences">Conferences</a>
        <a class="dropdown-item" href="/blog/vision">Computer Vision</a>
        <a class="dropdown-item" href="/blog/robotics">Robotics</a>
        <a class="dropdown-item" href="/blog/nlp">NLP</a>
        <a class="dropdown-item" href="/blog/ml">Machine Learning</a>
        <a class="dropdown-item" href="/blog/rl">Reinforcement Learning</a>

        </div>
      </li>
        
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/subscribe">Subscribe</a>
      </li>
      
      
      <li class="nav-item">
      <a class="nav-link" href="http://ai.stanford.edu/">SAIL</a>
      </li>
      
      </ul> 

    </div>

  </div>
</nav>

</header>

  
    <div class="content">
      

<article>

  <header id="main">
    
    <h1 id="post_title">Learning from Language Explanations</h1>
    <p class="meta">
    <a href="https://cs.stanford.edu/~muj/">Jesse Mu</a> and <a href="https://murtyshikhar.github.io/">Shikhar Murty</a>
    <div class="post-date">November 23, 2020</div>
    </p>
  <hr>
  </header>


  <section class="post-content">
  
    <p>Imagine you’re a machine learning practitioner and you want to solve some classification problem, like classifying groups of colored squares as being either 1s or 0s. Here’s what you would typically do: collect a large dataset of examples, label the data, and train a classifier:</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 700px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/examples.jpg" /></p>
</div></figure>

<p><em>But humans don’t learn like this</em>. We have a very powerful and intuitive mechanism for communicating information about the world - <strong>language</strong>!</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 500px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/language.jpg" /></p>
</div></figure>

<p>With just the phrase <em>at least 2 red squares</em>, we’ve summarized the entire dataset presented above in a much more efficient manner.</p>

<p><strong>Language is a crucial medium for human learning:</strong> we use it to <a href="https://www.npr.org/2010/01/18/122701268/i-have-a-dream-speech-in-its-entirety">convey beliefs</a> about the world, <a href="https://www.nature.com/articles/ncomms7029">teach others</a>, and describe things that are hard to <a href="https://en.wikipedia.org/wiki/Saturn">experience directly</a>. Thus, language ought to be a simple and effective way to supervise machine learning models. Yet past approaches to learning from language have struggled to scale up to the general tasks targeted by modern deep learning systems and the freeform language explanations used in these domains. In two short papers presented at ACL 2020 this year, we use deep neural models to learn from language explanations to help tackle a variety of challenging tasks in natural language processing (NLP) and computer vision.</p>

<ul>
  <li><a href="https://arxiv.org/abs/2005.01932">ExpBERT: Representation Engineering with Natural Language Explanations</a></li>
  <li><a href="https://arxiv.org/abs/1911.02683">Shaping Visual Representations with Language for Few-shot Classification</a></li>
</ul>

<h3 id="whats-the-challenge"><strong>What’s the challenge?</strong></h3>

<p>Given that language is such an intuitive interface for humans to teach others,
why is it so hard to use language for machine learning?</p>

<p>The principal challenge is the <a href="https://arxiv.org/html/cs/9906002">grounding
problem</a>: understanding language
explanations in the context of other inputs. Building models that can
understand rich and ambiguous language is tricky enough, but building models
that can relate language to the surrounding world is even more challenging. For
instance, given the explanation <em>at least two red squares</em>, a model must not
only understand the terms <em>red</em> and <em>square</em>, but also how they refer to
particular parts of (often complex) inputs.</p>

<p>Past work (<a href="https://www.aclweb.org/anthology/D17-1161">1</a>,
<a href="https://www.aclweb.org/anthology/P18-1029.pdf">2</a>,
<a href="https://arxiv.org/abs/1805.03818">3</a>) has relied on <a href="https://cs.stanford.edu/~pliang/papers/executable-cacm2016.pdf">semantic
parsers</a> which
convert natural language statements (e.g. <em>at least two red squares</em>) to formal
logical representations (e.g. <code class="highlighter-rouge">Count(Square AND Red) &gt; 2</code>). If we can easily
check whether explanations apply to our inputs by executing these logical
formulas, we can use our explanations as features to train our model.
However, semantic parsers only work on simple domains
where we can hand-engineer a logical grammar of explanations we might expect to
see. They struggle to handle richer and vaguer language or scale up to more
complex inputs, such as images.</p>

<p>Fortunately, modern deep neural language models such as
<a href="https://arxiv.org/abs/1810.04805">BERT</a> are beginning to show promise at
solving many language understanding tasks. Our papers propose to alleviate the
grounding problem by using neural language models that are either trained to
ground language explanations in the domain of interest, or come pre-trained
with general-purpose “knowledge” that can be used to interpret explanations. We
will show that these neural models allow us to learn from richer and more
diverse language for more challenging settings.</p>

<h3 id="representation-engineering-with-natural-language-explanations"><strong>Representation Engineering with Natural Language Explanations</strong></h3>

<p>In our <a href="https://arxiv.org/abs/2005.01932">first paper</a>, we examine how to build text classifiers with language
explanations.
Consider the task of <em>relation extraction</em>, where we are given a
short paragraph and must identify whether two people mentioned in the
paragraph are <strong>married</strong>. While state-of-the-art NLP models can likely solve
this task from data alone, humans might use language to describe ways to tell
whether two people are married—for example, <em>people who go on honeymoons are
typically married</em>. Can such language explanations be used to train better
classifiers?</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 700px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/expbert_dataset.jpg" /></p>
</div></figure>

<p>In the same way that we might take an input <script type="math/tex">x</script>, and extract features (e.g.
the presence of certain words) to train a model, we can use explanations to
provide additional features. For example, knowing that honeymoons are relevant
for this task, if we can create a honeymoon feature that reliably activates
whenever the two people in a paragraph are described as going on a honeymoon,
this should be useful signal for training a better model.</p>

<p>But creating such features requires some sort of explanation <strong>interpretation</strong>
mechanism that tells us whether an explanation is true for an input. Semantic
parsers are one such tool: given <em><script type="math/tex">A</script> and <script type="math/tex">B</script> went on honeymoon</em>, we could
parse this explanation into a logical form which, when run on an input,
produces 1 if the word <em>honeymoon</em> appears between <script type="math/tex">A</script> and <script type="math/tex">B</script>. But what about
a vaguer explanation like <em><script type="math/tex">A</script> and <script type="math/tex">B</script> are in love</em>? How can we parse this?</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 800px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/semantic_parsing_examples.jpg" /></p>
</div></figure>

<p>While semantic parsing is efficient and accurate in small domains, it can be
overly <em>brittle</em>, as it can only interpret explanations which adhere to a fixed
set of grammatical rules and functions that we must specify in advance (e.g.
<code class="highlighter-rouge">contains</code> and <code class="highlighter-rouge">extract_text</code>).
Instead, we turn to the soft reasoning
capabilities of <a href="https://arxiv.org/abs/1810.04805">BERT</a>, a neural language model. BERT is particularly effective
at the task of <em>textual entailment</em>: determining whether a sentence implies or
contradicts another sentence (e.g. does <em>She ate pizza</em> imply that <em>She ate
food?</em> Yes!). In our proposed <strong>ExpBERT</strong> model, we take a BERT model
trained for textual entailment, and instead ask it to identify whether a
paragraph in our task <em>entails</em> an explanation. The features produced by BERT
during this process replace the indicator features produced by the semantic
parser above.</p>

<figure class="figure"><div class="figure__main">
<video class="postimage_unpadded" style="max-width: 800px" autoplay="" muted="" loop="" playsinline="">
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/expbert.webm" type="video/webm" />
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/expbert.mp4" type="video/mp4" />
    <p>Your browser doesn't support HTML5 video. Here is a <a href="/blog/assets/img/posts/2020-11-23-learning-from-language/expbert.mp4">link to the video</a> instead, which you can download and run with a player like <a href="https://www.videolan.org/vlc/index.html">VLC</a></p>
</video>
</div></figure>

<p>Does the soft reasoning power of BERT improve over semantic parsing? On the
marriage identification task, we find that <strong>ExpBERT</strong> leads to substantial
improvements over a classifier that is trained on the input features only (No
Explanations). Importantly, using a semantic parser to try to parse
explanations doesn’t help much, since there are general explanations (<em>in
love</em>) that are difficult to convert to logical forms.</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 285px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/expbert_results.jpg" /></p>
</div></figure>

<p>In the full paper, we compare to more baselines, explore larger relation
extraction tasks (e.g. <a href="https://nlp.stanford.edu/projects/tacred/">TACRED</a>),
conduct ablation studies to understand what kinds of explanations are
important, and examine how much more efficient explanations are compared to
additional data.</p>

<h3 id="shaping-visual-representations-with-language"><strong>Shaping Visual Representations with Language</strong></h3>

<p>The work we’ve just described uses natural language explanations for a single
task like marriage identification.  However, <a href="https://plato.stanford.edu/entries/language-thought/">work in cognitive
science</a> suggests that
language also equips us with the right features and abstractions that help us
solve <em>future</em> tasks.
For example, explanations that indicate whether person <script type="math/tex">A</script> is married to
<script type="math/tex">B</script> also highlight other concepts that are crucial to human relationships:
<em>children</em>, <em>daughters</em>, <em>honeymoons</em>, and more. Knowing these additional
concepts are not just useful for identifying married people; they are also
important if we would later like to identify other relationships
(e.g. <em>siblings</em>, <em>mother</em>, <em>father</em>).</p>

<p>In machine learning, we might ask: how can language point out the right
features for challenging and underspecified domains, if we
ultimately wish to solve <em>new tasks</em> where no language is available? In our
<a href="https://arxiv.org/abs/1911.02683">second paper</a>, we explore this setting,
additionally increasing the challenge by seeing whether language can improve
the learning of representations across modalities—here, vision.</p>

<p>We’re specifically interested in few-shot visual reasoning tasks like the following (here, from the <a href="https://arxiv.org/abs/1704.04517">ShapeWorld</a> dataset):</p>

<figure class="figure"><div class="figure__main">
<video class="postimage_unpadded" style="max-width: 500px" autoplay="" muted="" loop="" playsinline="">
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/shapeworld.webm" type="video/webm" />
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/shapeworld.mp4" type="video/mp4" />
    <p>Your browser doesn't support HTML5 video. Here is a <a href="/blog/assets/img/posts/2020-11-23-learning-from-language/shapeworld.mp4">link to the video</a> instead, which you can download and run with a player like <a href="https://www.videolan.org/vlc/index.html">VLC</a></p>
</video>
</div></figure>

<p>Given a small training set of examples of a visual concept, the task is to
determine whether a held-out test image expresses the same concept.  Now, what
if we assume access to language explanations of the relevant visual concepts at
training time? Can we use these to learn a better model, <em>even if no language
is available at test time</em>?</p>

<p>We frame this as a <a href="https://arxiv.org/abs/1904.04232"><em>meta-learning</em></a> task:
instead of training and testing a model on a single task, we
train a model on a <em>set</em> of tasks, each with a small training set and
an accompanying language description (the <em>meta-train</em> set). We then test
generalization to a <em>meta-test</em> set of unseen tasks, for which no language is
available:</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 760px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/metalearning.jpg" /></p>
</div></figure>

<p>First, let’s look at how we might solve this task without language. One typical
approach is <strong>Prototype Networks</strong>, where we learn some model <script type="math/tex">f_\theta</script>
(here, a <a href="https://arxiv.org/abs/1409.1556">deep convolutional neural network</a>)
that embeds the training images, averages them, and compares to an embedding of
the test image:</p>

<figure class="figure"><div class="figure__main">
<video class="postimage_unpadded" style="max-width: 800px" autoplay="" muted="" loop="" playsinline="">
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/lsl.webm" type="video/webm" />
    <source src="/blog/assets/img/posts/2020-11-23-learning-from-language/lsl.mp4" type="video/mp4" />
    <p>Your browser doesn't support HTML5 video. Here is a <a href="/blog/assets/img/posts/2020-11-23-learning-from-language/lsl.mp4">link to the video</a> instead, which you can download and run with a player like <a href="https://www.videolan.org/vlc/index.html">VLC</a></p>
</video>
</div></figure>

<p>To use language, we propose a simple approach called <strong>Language Shaped Learning</strong>
(LSL): if we have access to explanations at training time, we encourage the
model to learn representations that are not only helpful for classification,
but are <em>predictive of the language explanations</em>. We do this by introducing an
<em>auxiliary</em> training objective (i.e. it is not related to the ultimate task of
interest), where we simultaneously train a recurrent neural network (RNN)
decoder to predict the explanation(s) from the representation of the
input images. Crucially, training this decoder depends on the
parameters of our image model <script type="math/tex">f_\theta</script>, so this process should encourage
<script type="math/tex">f_\theta</script> to better encode the features and abstractions exposed in
language.</p>

<p>In effect, we are training the model to “think out loud” when representing
concepts at training time. At test time, we simply discard the RNN decoder, and
do classification as normal with the “language-shaped” image embeddings.</p>

<p>We apply this model to both the ShapeWorld dataset described above, and a more
realistic <a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html">Birds</a>
dataset, with real images and human language:</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 800px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/birds.jpg" /></p>
</div></figure>

<p>In both cases, this auxiliary training objective improves performance over a
no-explanation baseline (<strong>Meta</strong>), and <a href="https://arxiv.org/abs/1711.00482"><em>Learning with Latent
Language</em></a> (<strong>L3</strong>), a similar model proposed
for this setting that uses language as a discrete bottleneck (see the paper for
details):</p>

<figure class="figure"><div class="figure__main">
<p><img class="postimage_unpadded" style="max-width: 400px" src="/blog/assets/img/posts/2020-11-23-learning-from-language/lsl_results.jpg" /></p>
</div></figure>

<p>In the full paper, we also explore which <em>parts</em> of language are most important
(spoiler: a little bit of everything), and <em>how much</em> language is needed for
LSL to improve over models that don’t use language (spoiler: surprisingly little!)</p>

<h3 id="moving-forward"><strong>Moving Forward</strong></h3>

<p>As NLP systems grow in their ability to understand and produce language, so too
grows the potential for machine learning systems to <em>learn from language</em> to
solve other challenging tasks. In the papers above, we’ve shown that deep
neural language models can be used to successfully learn from language
explanations to improve generalization across a variety of tasks in vision and
NLP.</p>

<p>We think this is an exciting new avenue for training machine learning models,
and similar ideas are already being explored in areas such as reinforcement
learning (<a href="https://arxiv.org/abs/1910.08210">4</a>,
<a href="https://arxiv.org/abs/1906.03926">5</a>). We envision a future where in order to
solve a machine learning task, we no longer have to collect a large labeled
dataset, but instead interact naturally and expressively with a model in the
same way that humans have interacted with each other for millennia—<em>through
language</em>.</p>

<h3 id="acknowledgments"><strong>Acknowledgments</strong></h3>

<p>Thanks to our coauthors (Pang Wei Koh, Percy Liang, and Noah Goodman), and to
Nelson Liu, Pang Wei Koh, and the rest of the SAIL blog team for reviewing and
publishing this blog post. This research was supported in part by the <a href="https://research.fb.com/fellowship/">Facebook
Fellowship</a> (to Pang Wei Koh), the <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a> (to Jesse Mu), <a href="https://www.tri.global/">Toyota Research
Institute</a>, and the <a href="https://www.onr.navy.mil/">Office of Naval Research</a>.</p>

  
  </section>
  <hr>
  Keep on top of the latest SAIL Blog posts via <a class="social-icon" href="http://0.0.0.0:4000/blog/feed.xml">RSS <i class="fa fa-rss-square fa fa" title="Twitter"></i></a>, <a class="social-icon" href="https://twitter.com/StanfordAILab">Twitter <i class="fa fa-twitter-square fa fa" title="Twitter"></i></a>, or email:

<!-- Begin Mailchimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}
	/* Add your own Mailchimp form style overrides in your site stylesheet or in this style block.
	   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="https://stanford.us19.list-manage.com/subscribe/post?u=3a6484754abf2fc18724ec835&amp;id=028823e92b" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	
	<input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_3a6484754abf2fc18724ec835_028823e92b" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->



  <!-- Social media shares -->
  <div class="share-buttons">
    <ul class="share-buttons">
        <div class="meta">Share</div>
        
        <li>
            <a href="https://www.facebook.com/sharer/sharer.php?u=http://0.0.0.0:4000/blog/learning-from-language/" target="_blank" title="Share on Facebook">
			<i class="fa fa-facebook-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Facebook</span>
		</a>
        </li>
         
        <li>
            <a href="https://twitter.com/intent/tweet?source=http://0.0.0.0:4000/blog/learning-from-language/&text=Learning+from+Language+Explanations%20%7C%20SAIL+Blog:%20http://0.0.0.0:4000/blog/learning-from-language/" target="_blank" title="Tweet">
			<i class="fa fa-twitter-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Tweet</span>
		</a>
        </li>
            
        <li>
            <a href="https://getpocket.com/save?url=http://0.0.0.0:4000/blog/learning-from-language/&title=Learning+from+Language+Explanations%20%7C%20SAIL+Blog" target="_blank" title="Add to Pocket">
			<i class="fa fa fa-get-pocket fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Add to Pocket</span>
		</a>
        </li>
         
        <li>
            <a href="http://www.reddit.com/submit?url=http://0.0.0.0:4000/blog/learning-from-language/&title=Learning+from+Language+Explanations%20%7C%20SAIL+Blog" target="_blank" title="Share on Reddit">
			<i class="fa fa-reddit-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Reddit</span>
		</a>
        </li>
           
        <li>
            <a href="mailto:?subject=Learning+from+Language+Explanations%20%7C%20SAIL+Blog&body=:%20http://0.0.0.0:4000/blog/learning-from-language/" target="_blank" title="Email">
			<i class="fa fa-envelope-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Email</span>
		</a>
        </li>
        
    </ul>
</div>

  <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/blog/tags#computer+vision">
      <p><i class="fa fa-tag fa-fw"></i> computer vision</p>
    </a>
    
    <a class="button" href="/blog/tags#explanation">
      <p><i class="fa fa-tag fa-fw"></i> explanation</p>
    </a>
    
    <a class="button" href="/blog/tags#grounding">
      <p><i class="fa fa-tag fa-fw"></i> grounding</p>
    </a>
    
    <a class="button" href="/blog/tags#machine+learning">
      <p><i class="fa fa-tag fa-fw"></i> machine learning</p>
    </a>
    
    <a class="button" href="/blog/tags#ml">
      <p><i class="fa fa-tag fa-fw"></i> ml</p>
    </a>
    
    <a class="button" href="/blog/tags#nlp">
      <p><i class="fa fa-tag fa-fw"></i> nlp</p>
    </a>
    
  </div>
</footer>

</article>

<!-- Disqus -->


<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <a href="/blog/corl-2020/">
      <p>Previous post</p>
        Stanford AI Lab Papers and Talks at CoRL 2020
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <a href="/blog/Bluepeoplevs.Neycity/">
      <p>Next post</p>
        Blue People v. City of Ney
      </a>
  </div>
  
</div>



    </div>
    <hr>
<footer class="site-footer">
    
   <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        
<li>
	<a href="http://0.0.0.0:4000/blog/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>







































<li>
	<a href="https://twitter.com/StanfordAILab" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








        </ul>
    </div>
    <p class="text">&copy; 2019 Stanford AI Lab
</p>
 
</footer>



  </body>
</html>
