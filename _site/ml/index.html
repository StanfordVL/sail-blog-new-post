<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/blog/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">

    <!--Favicon-->
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/blog/assets/img/favicon-16x16.png" sizes="16x16" />

    <!-- Canonical -->
    <link rel="canonical" href="http://0.0.0.0:4000/blog/ml/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="The Stanford AI Lab Blog" href="http://0.0.0.0:4000/blog/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/font-awesome.min.css">
    
    <!-- Bootstrap-3.3.7 isolation CSS -->
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">


    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
    
    <!-- JQuery 2.2.4 -->
    <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/bigfoot-number.css">
    <script type="text/javascript" src="/blog/assets/js/vendor/bigfoot.min.js"></script>
    <script type="text/javascript">
    $(document).ready(function() { 
      $.bigfoot();
      
    window.onload = function() {

        var videos = document.getElementsByTagName("video"),
            fraction = 0.8;

        function checkScroll() {

            for (var i = 0; i < videos.length; i++) {

                var video = videos[i];

                var x = video.offsetLeft,
                    y = video.offsetTop,
                    w = video.offsetWidth,
                    h = video.offsetHeight,
                    r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }

        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    }
    }); 
    </script>
    


    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/blog/assets/css/vendor/katex.min.css">
    <script src="/blog/assets/js/vendor/katex.min.js">
    </script>
    
    
    
    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-129018108-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Machine Learning Posts | SAIL Blog</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Machine Learning Posts" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The official Stanford AI Lab blog" />
<meta property="og:description" content="The official Stanford AI Lab blog" />
<link rel="canonical" href="http://0.0.0.0:4000/blog/ml/" />
<meta property="og:url" content="http://0.0.0.0:4000/blog/ml/" />
<meta property="og:site_name" content="SAIL Blog" />
<link rel="next" href="http://0.0.0.0:4000/blog/ml/page/2/index.html" />
<script type="application/ld+json">
{"description":"The official Stanford AI Lab blog","@type":"WebPage","url":"http://0.0.0.0:4000/blog/ml/","headline":"Machine Learning Posts","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    
    <!-- Manual seo tags -->
    <title>Machine Learning Posts | The Stanford AI Lab Blog</title>
    <meta name="description" content="The Stanford AI Lab (SAIL) Blog is a place for SAIL students, faculty, and researchers to share our work with the general public.">
    
    <!-- Twitter Cards -->
    <meta name="twitter:title" content="Machine Learning Posts">
    
    <meta name="twitter:description" content="The Stanford AI Lab (SAIL) Blog is a place for SAIL students, faculty, and researchers to share our work with the general public.">
    
    <meta name="twitter:creator" content="@StanfordAILab">
     
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="http://0.0.0.0:4000/blog/assets/img/sail-logo.png">
    <meta name="og:image" content="http://0.0.0.0:4000/blog/assets/img/sail-logo.png">
    
</head>

  <body class="category_posts-body">
      <!-- Toggle menu -->
<header class="site-header">

<nav class="clear navbar navbar-expand-lg navbar-light bg-white flex-column flex-md-row bd-navbar fixed-top" id="main_nav">
  
  <div class="container">

    <a class="navbar-brand mr-0 mr-md-2 text-black d-flex align-items-center" href="/blog/" aria-label="Bootstrap">
    
	  <div class="branding">
	    <a href="http://ai.stanford.edu/">
	      <img class="avatar" src="/blog/assets/img/sail-logo.png" alt=""/>
		  </a>

      <a href="/blog/">
	      <h1 class="site-title">
			    The Stanford AI Lab Blog
		    </h1> 
		  </a>
	  </div>
    
    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    <div class="collapse navbar-collapse" id="navbarResponsive">

      <ul class="navbar-nav ml-auto">
      
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/about">About</a>
      </li>
      
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
        <div class="dropdown-menu">
        <a class="dropdown-item" href="/blog/">All</a>
        <a class="dropdown-item" href="/blog/conferences">Conferences</a>
        <a class="dropdown-item" href="/blog/vision">Computer Vision</a>
        <a class="dropdown-item" href="/blog/robotics">Robotics</a>
        <a class="dropdown-item" href="/blog/nlp">NLP</a>
        <a class="dropdown-item" href="/blog/ml">Machine Learning</a>
        <a class="dropdown-item" href="/blog/rl">Reinforcement Learning</a>

        </div>
      </li>
        
      
      <li class="nav-item">
      <a class="nav-link" href="/blog/subscribe">Subscribe</a>
      </li>
      
      
      <li class="nav-item">
      <a class="nav-link" href="http://ai.stanford.edu/">SAIL</a>
      </li>
      
      </ul> 

    </div>

  </div>
</nav>

</header>

  
    <div class="content">
      <div class="home">
  <div class="posts">
  <br>
    <header id="main">
  <h1 id="Machine+Learning+Posts" class="title">
      Machine Learning Posts
  </h1>
  
  
  <hr>
</header>

    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-11-23-learning-from-language/thumb.jpg">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/learning-from-language/">
              <h2> Learning from Language Explanations </h2>
            </a>

             <p class="meta">
              <a href="https://cs.stanford.edu/~muj/">Jesse Mu</a> and <a href="https://murtyshikhar.github.io/">Shikhar Murty</a>
              <!-- November 23, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Language is a crucial way for humans to teach other humans. Can we use language to teach machines?
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/learning-from-language/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-11-08-DrRepair/graph.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/DrRepair/">
              <h2> Learning to Fix Programs from Error Messages </h2>
            </a>

             <p class="meta">
              <a href="https://michiyasunaga.github.io">Michihiro Yasunaga</a>
              <!-- November 8, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We study how to use machine learning to repair programs from error messages, and introduce a promising approach that leverages program-feedback graphs and self-supervised learning.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/DrRepair/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-11-05-adaptive-risk-minimization/intro.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/adaptive-risk-minimization/">
              <h2> Adapting on the Fly to Test Time Distribution Shift </h2>
            </a>

             <p class="meta">
              <a href="http://marvinzhang.com">Marvin Zhang</a>
              <!-- November 5, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We meta-learn models that can use unlabeled test data to adapt to group distribution shift.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/adaptive-risk-minimization/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-10-07-gti/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/gti/">
              <h2> GTI: Learning to Generalize Across Long-Horizon Tasks from Human Demonstrations </h2>
            </a>

             <p class="meta">
              <a href="http://web.stanford.edu/~amandlek/">Ajay Mandlekar</a>, <a href="https://cs.stanford.edu/~danfei/">Danfei Xu</a>
              <!-- October 7, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We developed Generalization Through Imitation (GTI) - an algorithm for learning visuomotor control from human demonstrations and generalizing to new long-horizon tasks by leveraging latent compositional structures.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/gti/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-08-25-black-box-safety-validation/formulation.jpg">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/black-box-safety-validation/">
              <h2> Safety Validation of Black-Box Autonomous Systems </h2>
            </a>

             <p class="meta">
              <a href="http://anthonylcorso.com/">Anthony L. Corso</a>
              <!-- August 31, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Validation of safety-critical autonomous systems is necessary before deployment and is made possible by black-box validation strategies. In this blog post, we provide a model for black-box safety validation and survey the literature to uncover the most effective validation techniques.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/black-box-safety-validation/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-08-23-meta-exploration/coupling.svg">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/meta-exploration/">
              <h2> Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning </h2>
            </a>

             <p class="meta">
              <a href='https://cs.stanford.edu/~evanliu'>Evan Zheran Liu</a>
              <!-- August 26, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Adapting to new environments and tasks (e.g., cooking in a new kitchen) requires first gathering information via exploration (e.g., finding the ingredients). We identify a chicken-and-egg coupling problem that prevents existing approaches from effectively exploring, and we solve this with DREAM.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/meta-exploration/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-06-25-trajectory-forecasting/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/trajectory-forecasting/">
              <h2> Back to the Future: Planning-Aware Trajectory Forecasting for Autonomous Driving </h2>
            </a>

             <p class="meta">
              <a href="http://www.borisivanovic.com">Boris Ivanovic</a>
              <!-- June 25, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Recent advances in deep generative modeling have brought forth a paradigm shift in trajectory forecasting. In this blog post, we provide an overview of existing work, highlight new opportunities, and present our latest work on developing methods that are cognizant of their downstream use cases.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/trajectory-forecasting/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog//assets/img/posts/2020-05-18-selfsupervised-multimodal/intro.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/selfsupervised-multimodal/">
              <h2> Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks  </h2>
            </a>

             <p class="meta">
              <a href="http://stanford.edu/~mishlee/">Michelle A. Lee</a>
              <!-- May 18, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Contact-rich manipulation tasks in unstructured environments often require both tactile and visual feedback. In this blog post, we introduce how to use self-supervision to learn a compact and multimodal representation of vision and touch.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/selfsupervised-multimodal/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-05-06-ntp-ntg/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/ntp-ntg/">
              <h2> Leveraging Compositionality for One-Shot Imitation Learning </h2>
            </a>

             <p class="meta">
              <a href="http://ai.stanford.edu/~dahuang/">De-An Huang</a>, <a href="https://cs.stanford.edu/~danfei/">Danfei Xu</a>
              <!-- May 6, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  We introduce a class of algorithms that solve long-horizon one-shot imitation learning by leveraging compositional priors.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/ntp-ntg/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
      
      <div class="post-teaser">
        
        <div class="post-img">

        
          <img src="https://ai.stanford.edu/blog/assets/img/posts/2020-04-20-data-augmentation/thumbnail.png">
        

        </div>
        
        <div class="info">
          <header>
            <a class="post-link" href="/blog/data-augmentation/">
              <h2> Automating Data Augmentation: Practice, Theory and New Direction </h2>
            </a>

             <p class="meta">
              <a href='http://yixuanli.net/'>Sharon Y. Li</a>
              <!-- April 24, 2020 -->
            </p>
          </header>
          <div class="excerpt">
            <!--  -->
            <div class="excerpt-text">
                
                  Data augmentation is a de facto technique used in nearly every state-of-the-art machine learning model. In this blog post, we provide an overview of recent work on the practice, theory and new direction of data augmentation research.
                
            </div>
            <div class="excerpt-continue">
              <a class="button" href="/blog/data-augmentation/">
                Continue reading
              </a>
            </div>
          </div>
        </div>
      </div>
      
    
  </div>

  
  <div class="paginate pager">

      

      
          <a href="/blog/ml/page/2/index.html" class="button" >
          Next
          <i class="fa fa-chevron-right"></i>
          </a>
      

  </div>
  

</div>


    </div>
    <hr>
<footer class="site-footer">
    
   <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        
<li>
	<a href="http://0.0.0.0:4000/blog/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>







































<li>
	<a href="https://twitter.com/StanfordAILab" title="Follow on Twitter" class="type">
        <span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>








        </ul>
    </div>
    <p class="text">&copy; 2019 Stanford AI Lab
</p>
 
</footer>



  </body>
</html>
